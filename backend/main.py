#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HistBenchæ•°æ®æµè§ˆåç«¯API
FastAPI + Pandas + é™æ€æ–‡ä»¶æœåŠ¡
"""

from fastapi import FastAPI, HTTPException, Query
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import os
from pathlib import Path
from typing import List, Optional
from pydantic import BaseModel
import mimetypes
from contextlib import asynccontextmanager
from fastapi.responses import FileResponse, StreamingResponse, JSONResponse
from io import BytesIO
from PIL import Image

# å…¨å±€å˜é‡å­˜å‚¨æ•°æ®
df = None

# OSS å…¬ç½‘å‰ç¼€
OSS_BASE_URL = "https://hisagent-0612.oss-cn-shanghai.aliyuncs.com/HistBench_complete"

@asynccontextmanager
async def lifespan(app: FastAPI):
    # åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ
    global df
    print("ğŸš€ åº”ç”¨å¯åŠ¨ï¼Œå¼€å§‹åŠ è½½æ•°æ®...")
    load_data()
    # ä¸å†æŒ‚è½½æœ¬åœ°åª’ä½“ç›®å½•ï¼Œä¹Ÿä¸æŠ¥é”™
    print("âœ… æ•°æ®åŠ è½½å®Œæˆï¼ˆæœªæŒ‚è½½æœ¬åœ°åª’ä½“ç›®å½•ï¼Œæ‰€æœ‰åª’ä½“è¯·è®¿é—®OSSç›´é“¾ï¼‰")
    yield
    # åº”ç”¨å…³é—­æ—¶æ‰§è¡Œ (å¦‚æœéœ€è¦)
    print("åº”ç”¨å…³é—­")

app = FastAPI(
    title="HistBench API",
    description="å†å²é¢˜ç›®æ•°æ®æµè§ˆAPI",
    version="1.0.0",
    lifespan=lifespan
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000", "http://127.0.0.1:3000",
        "http://localhost:3001", "http://127.0.0.1:3001", 
        "http://localhost:3002", "http://127.0.0.1:3002",
        "http://localhost:3003", "http://127.0.0.1:3003"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®æ–‡ä»¶è·¯å¾„
DATA_FILE = "data/processed/Sheet1.csv"
MEDIA_DIR = Path("data/raw/HistBench_complete")

# æ•°æ®æ¨¡å‹
class QuestionItem(BaseModel):
    task_id: int
    question: str
    level: int
    answer_type: str
    final_answer: str
    file_name: Optional[str] = None
    answer_explanation: Optional[str] = None
    media_files: List[str] = []

class QuestionResponse(BaseModel):
    total: int
    page: int
    per_page: int
    data: List[QuestionItem]

class StatsResponse(BaseModel):
    total_questions: int
    level_distribution: dict
    answer_type_distribution: dict
    has_media_count: int

class QuestionIndexItem(BaseModel):
    task_id: int
    level: int
    answer_type: str

def load_data():
    """åŠ è½½CSVæ•°æ®"""
    global df
    if df is None:
        try:
            df = pd.read_csv(DATA_FILE)
            # æ•°æ®æ¸…æ´—
            df = df.fillna("")
            # æ ‡å‡†åŒ–ç­”æ¡ˆç±»å‹
            df['Answer Type'] = df['Answer Type'].str.replace('Multiple Choice', 'multipleChoice')
            df['Answer Type'] = df['Answer Type'].str.replace('Multiple choice', 'multipleChoice')  
            df['Answer Type'] = df['Answer Type'].str.replace('mutipleChioce', 'multipleChoice')
            df['Answer Type'] = df['Answer Type'].str.replace('Exact match', 'exactMatch')
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æ¡è®°å½•")
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise e
    return df

def find_media_files(file_name: str) -> List[str]:
    """æ ¹æ®æ–‡ä»¶åç”Ÿæˆ OSS å…¬ç½‘ç›´é“¾ï¼ˆä¸ä¾èµ–æœ¬åœ°æ–‡ä»¶ï¼‰"""
    if not file_name:
        return []
    media_files = []
    file_names = [f.strip() for f in file_name.split(';') if f.strip()]
    for fname in file_names:
        # ç›´æ¥æ‹¼æ¥ OSS URL
        media_files.append(f"{OSS_BASE_URL}/{fname}")
    return media_files

@app.get("/", summary="APIæ ¹è·¯å¾„")
async def root():
    return {"message": "HistBench API æœåŠ¡æ­£åœ¨è¿è¡Œ", "version": "1.0.0"}

@app.get("/stats", response_model=StatsResponse, summary="è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯")
async def get_stats():
    """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    data = load_data()
    
    level_dist = data['Level'].value_counts().to_dict()
    answer_type_dist = data['Answer Type'].value_counts().to_dict()
    has_media = (data['file_name'] != "").sum()
    
    return StatsResponse(
        total_questions=len(data),
        level_distribution=level_dist,
        answer_type_distribution=answer_type_dist,
        has_media_count=int(has_media)
    )

@app.get("/questions", response_model=QuestionResponse, summary="è·å–é¢˜ç›®åˆ—è¡¨")
async def get_questions(
    page: int = Query(1, ge=1, description="é¡µç "),
    per_page: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    level: Optional[int] = Query(None, description="éš¾åº¦çº§åˆ«ç­›é€‰"),
    answer_type: Optional[str] = Query(None, description="ç­”æ¡ˆç±»å‹ç­›é€‰"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    has_media: Optional[bool] = Query(None, description="æ˜¯å¦æœ‰åª’ä½“æ–‡ä»¶")
):
    """è·å–é¢˜ç›®åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µå’Œç­›é€‰"""
    data = load_data().copy()
    
    # ç­›é€‰é€»è¾‘
    if level is not None:
        data = data[data['Level'] == level]
    
    if answer_type:
        data = data[data['Answer Type'] == answer_type]
    
    if search:
        # åœ¨é—®é¢˜å’Œç­”æ¡ˆä¸­æœç´¢
        mask = (data['Question'].str.contains(search, case=False, na=False) | 
                data['Final answer'].str.contains(search, case=False, na=False))
        data = data[mask]
    
    if has_media is not None:
        if has_media:
            data = data[data['file_name'] != ""]
        else:
            data = data[data['file_name'] == ""]
    
    # åˆ†é¡µ
    total = len(data)
    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page
    page_data = data.iloc[start_idx:end_idx]
    
    # è½¬æ¢ä¸ºå“åº”æ ¼å¼
    questions = []
    for _, row in page_data.iterrows():
        media_files = find_media_files(row['file_name'])
        
        question = QuestionItem(
            task_id=int(row['task_id']),
            question=row['Question'],
            level=int(row['Level']),
            answer_type=row['Answer Type'],
            final_answer=row['Final answer'],
            file_name=row['file_name'] if row['file_name'] else None,
            answer_explanation=row['Answer Explanation'] if row['Answer Explanation'] else None,
            media_files=media_files
        )
        questions.append(question)
    
    return QuestionResponse(
        total=total,
        page=page,
        per_page=per_page,
        data=questions
    )

@app.get("/questions/index", response_model=List[QuestionIndexItem], summary="è·å–æ‰€æœ‰é¢˜ç›®çš„ç´¢å¼•ä¿¡æ¯")
async def get_questions_index():
    """è·å–æ‰€æœ‰é¢˜ç›®çš„æ ¸å¿ƒå…ƒæ•°æ®ï¼Œç”¨äºç´¢å¼•é¢æ¿"""
    data = load_data()
    
    # åªé€‰æ‹©éœ€è¦çš„åˆ—
    index_data = data[['task_id', 'Level', 'Answer Type']].copy()
    index_data.rename(columns={'Level': 'level', 'Answer Type': 'answer_type'}, inplace=True)
    
    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    result = index_data.to_dict(orient='records')
    return result

@app.get("/questions/{task_id}", response_model=QuestionItem, summary="è·å–å•ä¸ªé¢˜ç›®è¯¦æƒ…")
async def get_question(task_id: int):
    """è·å–å•ä¸ªé¢˜ç›®çš„è¯¦ç»†ä¿¡æ¯"""
    data = load_data()
    question_data = data[data['task_id'] == task_id]
    
    if question_data.empty:
        raise HTTPException(status_code=404, detail="é¢˜ç›®ä¸å­˜åœ¨")
    
    row = question_data.iloc[0]
    media_files = find_media_files(row['file_name'])
    
    return QuestionItem(
        task_id=int(row['task_id']),
        question=row['Question'],
        level=int(row['Level']),
        answer_type=row['Answer Type'],
        final_answer=row['Final answer'],
        file_name=row['file_name'] if row['file_name'] else None,
        answer_explanation=row['Answer Explanation'] if row['Answer Explanation'] else None,
        media_files=media_files
    )

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨HistBench APIæœåŠ¡ (å¼€å‘æ¨¡å¼)...")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸŒ å‰ç«¯åœ°å€: http://localhost:3000")
    # æ³¨æ„: åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ¨èä½¿ç”¨Gunicornç­‰WSGIæœåŠ¡å™¨æ¥è¿è¡ŒUvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True, app_dir="backend") 