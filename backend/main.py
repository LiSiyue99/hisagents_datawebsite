#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HistBenchæ•°æ®æµè§ˆåç«¯API
FastAPI + Pandas + é™æ€æ–‡ä»¶æœåŠ¡
"""

from fastapi import FastAPI, HTTPException, Query
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import os
from pathlib import Path
from typing import List, Optional
from pydantic import BaseModel
import mimetypes
from contextlib import asynccontextmanager
from fastapi.responses import FileResponse, StreamingResponse, JSONResponse
from io import BytesIO
from PIL import Image

# å…¨å±€å˜é‡å­˜å‚¨æ•°æ®
df = None

# OSS å…¬ç½‘å‰ç¼€
OSS_BASE_URL = "https://hisagent-0612.oss-cn-shanghai.aliyuncs.com/HistBench_complete"

@asynccontextmanager
async def lifespan(app: FastAPI):
    # åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ
    global df
    print("ğŸš€ åº”ç”¨å¯åŠ¨ï¼Œå¼€å§‹åŠ è½½æ•°æ®...")
    load_data()
    # ä¸å†æŒ‚è½½æœ¬åœ°åª’ä½“ç›®å½•ï¼Œä¹Ÿä¸æŠ¥é”™
    print("âœ… æ•°æ®åŠ è½½å®Œæˆï¼ˆæœªæŒ‚è½½æœ¬åœ°åª’ä½“ç›®å½•ï¼Œæ‰€æœ‰åª’ä½“è¯·è®¿é—®OSSç›´é“¾ï¼‰")
    yield
    # åº”ç”¨å…³é—­æ—¶æ‰§è¡Œ (å¦‚æœéœ€è¦)
    print("åº”ç”¨å…³é—­")

app = FastAPI(
    title="HistBench API",
    description="å†å²é¢˜ç›®æ•°æ®æµè§ˆAPI",
    version="1.0.0",
    lifespan=lifespan
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000", "http://127.0.0.1:3000",
        "http://localhost:3001", "http://127.0.0.1:3001", 
        "http://localhost:3002", "http://127.0.0.1:3002",
        "http://localhost:3003", "http://127.0.0.1:3003"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®æ–‡ä»¶è·¯å¾„
DATA_FILE = "data/processed/Sheet1.csv"
MEDIA_DIR = Path("data/raw/HistBench_complete")

# æ•°æ®æ¨¡å‹
class QuestionItem(BaseModel):
    task_id: int
    question: str
    level: int
    answer_type: str
    final_answer: str
    file_name: Optional[str] = None
    answer_explanation: Optional[str] = None
    media_files: List[str] = []

class QuestionResponse(BaseModel):
    total: int
    page: int
    per_page: int
    data: List[QuestionItem]

class StatsResponse(BaseModel):
    total_questions: int
    level_distribution: dict
    answer_type_distribution: dict
    media_type_distribution: dict

class QuestionIndexItem(BaseModel):
    task_id: int
    level: int
    answer_type: str

def get_media_type(filename: str) -> str:
    """ä»æ–‡ä»¶åçŒœæµ‹åª’ä½“ç±»å‹"""
    if not isinstance(filename, str):
        return 'other'
    
    # ç‰¹æ®Šå¤„ç†é—®é¢˜93å’Œ94çš„reference
    if filename.lower().startswith('reference:'):
        return 'reference'
    
    if '.' not in filename:
        return 'other'
        
    ext = filename.lower().split('.')[-1]
    if ext in ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'webp', 'heic', 'tif', 'tiff']:
        return 'image'
    if ext in ['mp4', 'mov', 'avi', 'mkv', 'webm']:
        return 'video'
    if ext in ['mp3', 'wav', 'ogg', 'flac', 'aac', 'm4a']:
        return 'audio'
    if ext in ['pdf', 'doc', 'docx']:
        return 'document'
    return 'other'

def process_media_files(file_name: str) -> List[str]:
    """å¤„ç†åª’ä½“æ–‡ä»¶åï¼ŒåŒ…æ‹¬ç‰¹æ®Šçš„referenceæƒ…å†µ"""
    if not file_name:
        return []
    
    media_files = []
    file_names = [f.strip() for f in file_name.split(';') if f.strip()]
    
    for fname in file_names:
        if fname.lower().startswith('reference:'):
            # å¯¹äºreferenceï¼Œç›´æ¥è¿”å›æ–‡æœ¬å†…å®¹ï¼Œä¸æ·»åŠ ä»»ä½•URL
            media_files.append(fname)
        else:
            # å¯¹äºæ™®é€šåª’ä½“æ–‡ä»¶ï¼Œè¿”å›OSS URL
            media_files.append(f"{OSS_BASE_URL}/{fname}")
    
    return media_files

def load_data():
    """åŠ è½½CSVæ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†"""
    global df
    if df is None:
        try:
            df = pd.read_csv(DATA_FILE)
            # æ•°æ®æ¸…æ´—
            df = df.fillna("")
            # æ ‡å‡†åŒ–ç­”æ¡ˆç±»å‹
            df['Answer Type'] = df['Answer Type'].str.replace('Multiple Choice', 'multipleChoice')
            df['Answer Type'] = df['Answer Type'].str.replace('Multiple choice', 'multipleChoice')  
            df['Answer Type'] = df['Answer Type'].str.replace('mutipleChioce', 'multipleChoice')
            df['Answer Type'] = df['Answer Type'].str.replace('Exact match', 'exactMatch')
            
            # -- æ–°å¢ï¼šæå–åª’ä½“æ–‡ä»¶ç±»å‹ --
            def extract_media_types(file_name_str):
                if not file_name_str:
                    return []
                files = [f.strip() for f in file_name_str.split(';') if f.strip()]
                # ä½¿ç”¨ set æ¥å­˜å‚¨å”¯ä¸€ç±»å‹
                types = {get_media_type(f) for f in files}
                return list(types)

            df['media_types'] = df['file_name'].apply(extract_media_types)
            # --------------------------

            # ğŸ“Œ æ•°æ®åº“ç‰¹æ®Šä¿®å¤ï¼šä»»åŠ¡ 93 ä¸ 94 åª’ä½“åˆ—å…¶å®æ˜¯å‚è€ƒèµ„æ–™æ ‡é¢˜ï¼Œæ— æ‰©å±•åã€‚
            special_mask = df['task_id'].isin([93, 94])
            if special_mask.any():
                # å¦‚æœ file_name æ²¡æœ‰ reference å‰ç¼€ï¼Œåˆ™è¡¥å…¨
                df.loc[special_mask, 'file_name'] = df.loc[special_mask, 'file_name'].apply(
                    lambda x: x if str(x).lower().startswith('reference:') else f'reference: {x}'
                )
                # media_types å¼ºåˆ¶è®¾ä¸º reference
                df.loc[special_mask, 'media_types'] = [['reference']]*special_mask.sum()
            # --------------------------

            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æ¡è®°å½•")
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise e
    return df

def find_media_files(file_name: str) -> List[str]:
    """æ ¹æ®æ–‡ä»¶åç”Ÿæˆ OSS å…¬ç½‘ç›´é“¾ï¼ˆä¸ä¾èµ–æœ¬åœ°æ–‡ä»¶ï¼‰"""
    if not file_name:
        return []
    media_files = []
    file_names = [f.strip() for f in file_name.split(';') if f.strip()]
    for fname in file_names:
        # ç›´æ¥æ‹¼æ¥ OSS URL
        media_files.append(f"{OSS_BASE_URL}/{fname}")
    return media_files

@app.get("/", summary="APIæ ¹è·¯å¾„")
async def root():
    return {"message": "HistBench API æœåŠ¡æ­£åœ¨è¿è¡Œ", "version": "1.0.0"}

@app.get("/stats", response_model=StatsResponse, summary="è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯")
async def get_stats():
    """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    data = load_data()
    
    level_dist = data['Level'].value_counts().to_dict()
    answer_type_dist = data['Answer Type'].value_counts().to_dict()

    # -- æ›´æ–°ï¼šè®¡ç®—åª’ä½“ç±»å‹åˆ†å¸ƒ --
    allowed_types = {'image','video','audio','document','reference','other'}
    all_media_types = []
    for types_list in data['media_types']:
        # å…¼å®¹å¯èƒ½ä¸ºå­—ç¬¦ä¸²çš„å¼‚å¸¸æƒ…å†µ
        if isinstance(types_list, list):
            all_media_types.extend(types_list)
        elif isinstance(types_list, str):
            all_media_types.append(types_list)
    media_type_dist = pd.Series(all_media_types).value_counts().to_dict()
    # ä»…ä¿ç•™å…è®¸çš„ç±»åˆ«ï¼Œå…¶ä»–å½’ä¸º 'other'
    cleaned_dist = {}
    for k,v in media_type_dist.items():
        if k in allowed_types:
            cleaned_dist[k] = int(v)
        else:
            cleaned_dist['other'] = cleaned_dist.get('other',0)+int(v)
    media_type_dist = cleaned_dist
    # --------------------------
    
    return StatsResponse(
        total_questions=len(data),
        level_distribution=level_dist,
        answer_type_distribution=answer_type_dist,
        media_type_distribution=media_type_dist
    )

@app.get("/questions", response_model=QuestionResponse, summary="è·å–é¢˜ç›®åˆ—è¡¨")
async def get_questions(
    page: int = Query(1, ge=1, description="é¡µç "),
    per_page: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    level: Optional[int] = Query(None, description="éš¾åº¦çº§åˆ«ç­›é€‰"),
    answer_type: Optional[str] = Query(None, description="ç­”æ¡ˆç±»å‹ç­›é€‰"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    media_type: Optional[str] = Query(None, description="åª’ä½“ç±»å‹ç­›é€‰ (image, video, audio, document, reference)")
):
    """è·å–é¢˜ç›®åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µå’Œç­›é€‰"""
    data = load_data().copy()
    
    # ç­›é€‰é€»è¾‘
    if level is not None:
        data = data[data['Level'] == level]
    
    if answer_type:
        data = data[data['Answer Type'] == answer_type]
    
    if search:
        # åœ¨é—®é¢˜å’Œç­”æ¡ˆä¸­æœç´¢
        mask = (data['Question'].str.contains(search, case=False, na=False) | 
                data['Final answer'].str.contains(search, case=False, na=False))
        data = data[mask]
    
    if media_type:
        # ç­›é€‰åŒ…å«ç‰¹å®šåª’ä½“ç±»å‹çš„é¢˜ç›®
        data = data[data['media_types'].apply(lambda types: media_type in types)]
    
    # åˆ†é¡µ
    total = len(data)
    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page
    page_data = data.iloc[start_idx:end_idx]
    
    # è½¬æ¢ä¸ºå“åº”æ ¼å¼
    questions = []
    for _, row in page_data.iterrows():
        media_files = process_media_files(row['file_name'])
        
        question = QuestionItem(
            task_id=int(row['task_id']),
            question=row['Question'],
            level=int(row['Level']),
            answer_type=row['Answer Type'],
            final_answer=row['Final answer'],
            file_name=row['file_name'] if row['file_name'] else None,
            answer_explanation=row['Answer Explanation'] if row['Answer Explanation'] else None,
            media_files=media_files
        )
        questions.append(question)
    
    return QuestionResponse(
        total=total,
        page=page,
        per_page=per_page,
        data=questions
    )

@app.get("/questions/index", response_model=List[QuestionIndexItem], summary="è·å–æ‰€æœ‰é¢˜ç›®çš„ç´¢å¼•ä¿¡æ¯")
async def get_questions_index():
    """è·å–æ‰€æœ‰é¢˜ç›®çš„æ ¸å¿ƒå…ƒæ•°æ®ï¼Œç”¨äºç´¢å¼•é¢æ¿"""
    data = load_data()
    
    # åªé€‰æ‹©éœ€è¦çš„åˆ—
    index_data = data[['task_id', 'Level', 'Answer Type']].copy()
    index_data.rename(columns={'Level': 'level', 'Answer Type': 'answer_type'}, inplace=True)
    
    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    result = index_data.to_dict(orient='records')
    return result

@app.get("/questions/{task_id}", response_model=QuestionItem, summary="è·å–å•ä¸ªé¢˜ç›®è¯¦æƒ…")
async def get_question(task_id: int):
    """è·å–å•ä¸ªé¢˜ç›®çš„è¯¦ç»†ä¿¡æ¯"""
    data = load_data()
    question_data = data[data['task_id'] == task_id]
    
    if question_data.empty:
        raise HTTPException(status_code=404, detail="é¢˜ç›®ä¸å­˜åœ¨")
    
    row = question_data.iloc[0]
    media_files = process_media_files(row['file_name'])
    
    return QuestionItem(
        task_id=int(row['task_id']),
        question=row['Question'],
        level=int(row['Level']),
        answer_type=row['Answer Type'],
        final_answer=row['Final answer'],
        file_name=row['file_name'] if row['file_name'] else None,
        answer_explanation=row['Answer Explanation'] if row['Answer Explanation'] else None,
        media_files=media_files
    )

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨HistBench APIæœåŠ¡ (å¼€å‘æ¨¡å¼)...")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸŒ å‰ç«¯åœ°å€: http://localhost:3000")
    # æ³¨æ„: åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ¨èä½¿ç”¨Gunicornç­‰WSGIæœåŠ¡å™¨æ¥è¿è¡ŒUvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True, app_dir="backend") 